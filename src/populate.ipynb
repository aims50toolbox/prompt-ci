{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hhgttg2.txt\") as f:\n",
    "    hhgttg = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "texts = text_splitter.create_documents([hhgttg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3888"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = text_splitter.split_text(hhgttg)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Hitch Hiker's Guide to the Galaxy \\n\\nfor Jonny Brock and Clare Gorst  and all other Arlingtoniansfor tea, sympathy, and a sofa\\n\\n\\n\\nFar out in the uncharted backwaters of the unfashionable  end  of the  western  spiral  arm  of  the Galaxy lies a small unregarded yellow sun.\",\n",
       " 'Orbiting this at a distance of roughly ninety-two  million  miles is  an  utterly insignificant little blue green planet whose ape- descended life forms are so amazingly primitive that  they  still think digital watches are a pretty neat idea.',\n",
       " \"This planet has - or rather had - a problem, which was this: most of  the  people  on  it were unhappy for pretty much of the time. Many solutions were suggested for this problem, but most of these were  largely  concerned with the movements of small green pieces of paper, which is odd because on the whole it wasn't  the  small green pieces of paper that were unhappy.\",\n",
       " \"And so the problem remained; lots of the people  were  mean,  and most of them were miserable, even the ones with digital watches.\\n\\nMany were increasingly of the opinion that they'd all made a  big mistake  in  coming  down  from the trees in the first place. And some said that even the trees had been a bad move,  and  that  no one should ever have left the oceans.\",\n",
       " 'And then, one Thursday, nearly two thousand years after  one  man had  been nailed to a tree for saying how great it would be to be nice to people for a change, one girl sitting on  her  own  in  a small  cafe  in  Rickmansworth suddenly realized what it was that had been going wrong all this time, and she finally knew how  the world  could  be  made  a  good and happy place. This time it was right, it would work, and no one would  have  to  get  nailed  to anything.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/projects/AIMS5.0/stuff/vector/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/storage/projects/AIMS5.0/stuff/vector/.venv/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embed_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, db\n",
    "connections.connect(\n",
    "  alias=\"default\",\n",
    "  user='',\n",
    "  password='',\n",
    "  host='localhost',\n",
    "  port='19530'\n",
    ")\n",
    "\n",
    "database = db.create_database(\"embeddings\")\n",
    "db.using_database(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection\n",
    "chunk_uid = FieldSchema(\n",
    "  name=\"chunk_uid\",\n",
    "  dtype=DataType.INT64,\n",
    "  is_primary=True,\n",
    "  auto_id=True\n",
    ")\n",
    "chunk = FieldSchema(\n",
    "  name=\"chunk\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  max_length=CHUNK_SIZE,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"\"\n",
    ")\n",
    "chunk_embedding = FieldSchema(\n",
    "  name=\"chunk_embedding\",\n",
    "  dtype=DataType.FLOAT_VECTOR,\n",
    "  dim=384\n",
    ")\n",
    "\n",
    "schema = CollectionSchema(\n",
    "  fields=[chunk_uid, chunk, chunk_embedding],\n",
    "  description=\"Sentence embeddings\",\n",
    "  enable_dynamic_field=True\n",
    ")\n",
    "collection_name = \"chunks\"\n",
    "\n",
    "try:\n",
    "  chunks = Collection(\n",
    "      name=collection_name,\n",
    "      schema=schema,\n",
    "      using='default',\n",
    "      shards_num=2\n",
    "      )\n",
    "except Exception as inst:\n",
    "  print(\"Error: \" + str(inst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3888, (3888, 384))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embed_model.encode(texts)\n",
    "#print(embeddings)\n",
    "len(texts), embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mr = chunks.insert([texts,embeddings])\n",
    "    chunks.flush()\n",
    "    mr\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "\n",
    "chunks.create_index(\"chunk_embedding\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
